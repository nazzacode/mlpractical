\begin{thebibliography}{4}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Goodfellow et~al.(2013)Goodfellow, Warde-Farley, Mirza, Courville, and
  Bengio]{goodfellow2013maxout}
Goodfellow, Ian, Warde-Farley, David, Mirza, Mehdi, Courville, Aaron, and
  Bengio, Yoshua.
\newblock Maxout networks.
\newblock In \emph{International conference on machine learning}, pp.\
  1319--1327. PMLR, 2013.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{Goodfellow-et-al-2016}
Goodfellow, Ian, Bengio, Yoshua, and Courville, Aaron.
\newblock \emph{Deep Learning}.
\newblock MIT Press, 2016.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem[Ng(2004)]{ng2004feature}
Ng, Andrew~Y.
\newblock Feature selection, l1 vs. l2 regularization, and rotational
  invariance.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, pp.\ ~78, 2004.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex, Sutskever, Ilya, and
  Salakhutdinov, Ruslan.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The journal of machine learning research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\end{thebibliography}
